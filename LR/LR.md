# ä¸­å±±å¤§å­¦æ•°æ®ç§‘å­¦ä¸è®¡ç®—æœºå­¦é™¢

# ç§»åŠ¨ä¿¡æ¯å·¥ç¨‹ä¸“ä¸š-äººå·¥æ™ºèƒ½

# æœ¬ç§‘ç”Ÿå®éªŒæŠ¥å‘Š

ï¼ˆ2017-2018 å­¦å¹´ç§‹å­£å­¦æœŸï¼‰

è¯¾ç¨‹åç§°ï¼š**Artificial Intelligence**

## ä¸€ã€å®éªŒé¢˜ç›®

Logistic Regression Modelï¼šåˆ©ç”¨logistics å›å½’æ¨¡å‹è¿›è¡ŒäºŒåˆ†ç±»

## äºŒã€å®éªŒå†…å®¹

### 1.ç®—æ³•åŸç†

Logistic Regression Modelæ˜¯ä¸€ä¸ªåˆ†ç±»æ¨¡å‹ï¼Œæ˜¯ç ”ç©¶äºŒåˆ†ç±»é—®é¢˜å’Œä¸€äº›å½±å“å› ç´ ä¹‹é—´å…³ç³»çš„ä¸€ç§å¤šå˜é‡åˆ†ææ–¹æ³•ï¼Œè€Œä¸”Logistic Regressionåˆ†ç±»æ¨¡å‹æ˜¯ä¸€ä¸ªè½¯åˆ†ç±»æ¨¡å‹ã€‚åœ¨åˆ†ç±»æƒ…å½¢ä¸‹ï¼Œè¯¥æ¨¡å‹é€šè¿‡è®¡ç®—å½±å“å› ç´ çš„æƒé‡ï¼Œæ ¹æ®æƒé‡æ¥äº†è§£é¢„æµ‹ç›®æ ‡çš„å¯èƒ½æ€§ã€‚å¯¹äºä¸€ä¸ªå¾…åˆ†ç±»æ ·æœ¬$\vec{X}=\{x_1,x_2,..,x_n\}$ï¼Œåˆ©ç”¨Logistic Regressionåˆ†ç±»æ¨¡å‹æ±‚å¾—çš„$\vec{W}=\{w_0,w_1,w_2,...,w_n\}$å’Œå¾…åˆ†ç±»æ ·æœ¬è¿›è¡Œçº¿æ€§åŠ æƒå’Œå¾—åˆ°$x=w_0+w_1x_1+w_2x_2+...+w_nx_n$ï¼Œç„¶ååˆ©ç”¨sigmoidå‡½æ•°
$$
f(x)=\frac{1}{1+e^{-x}}\tag{1}
$$
å°†$x$æ˜ å°„åˆ°$(0,1)$ï¼Œæœ€åæ ¹æ®$f(x)$çš„å€¼æ¥å¯¹å¾…åˆ†ç±»æ ·æœ¬è¿›è¡Œåˆ†ç±»ã€‚



é’ˆå¯¹Logistic Regressionåˆ†ç±»æ¨¡å‹æ±‚$\vec{W}=\{w_0,w_1,w_2,...,w_n\}$ çš„é—®é¢˜ï¼Œé¦–å…ˆå®šä¹‰ç›®æ ‡å‡½æ•°å¦‚ä¸‹ï¼š
$$
f(x)=P(label|x)\in[0,1]\tag{2}
$$
å³å¯¹æŸä¸ªç‰¹å¾å‘é‡$\vec{x}$ï¼Œå®ƒå±äº$label$çš„æ¦‚ç‡ä¸ºå¤šå°‘ã€‚

å‡è®¾æœ‰$m$ä¸ªæ ·æœ¬ï¼Œæ ‡ç­¾åˆ†åˆ«ä¸º$y_1,y_2,...,y_n$ï¼Œè®¾$p_i=P(y_i=1|x_i)$ä¸ºç»™å®šæ¡ä»¶ä¸‹å¾—åˆ°$y_i=1$çš„æ¦‚ç‡ï¼ŒåŒæ ·ï¼Œå¯ä»¥å¾—åˆ°$P(y_i=1|x_i)=1-p_i$ï¼Œæ‰€ä»¥èƒ½å¤Ÿå‡†ç¡®é¢„æµ‹è¯¥æ ·æœ¬çš„æ¦‚ç‡ä¸º
$$
P(y_i)=p_i^{y_i}(1-p_i)^{1-y_i}\tag{3}
$$
ç”±äºæ ·æœ¬ä¹‹é—´ç›¸äº’ç‹¬ç«‹ï¼Œæ ¹æ®è´å¶æ–¯æ³•åˆ™ï¼Œå¯ä»¥å¾—åˆ°ä¼¼ç„¶å‡½æ•°ä¸ºï¼š
$$
\begin{split}
likelihood(logistic\quad h)\quad L(\vec{w})&\propto \prod_{i=1}^{m}P(y_n|x_n,\vec{w}) \\&= \prod_{i=1}^{m}(h(x_i))^{y_i}(1-h(x_i))^{1-y_i}
\end{split}
\tag{4}
$$
å…¶ä¸­$h(x)$æ˜¯åˆ©ç”¨logisticså‡½æ•°æ„é€ çš„æ–°çš„æ¨¡å‹ï¼š
$$
h(x)=\frac{1}{1+e^{-\vec{W}^Tx}}\tag{5}
$$
è¯¥æ¨¡å‹ä¸»è¦ç”¨æ¥å¯¹æ ·æœ¬å„ä¸ªå±æ€§åŠ æƒå’Œè¿›è¡Œæ¦‚ç‡è¯„ä¼°ã€‚

æˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯æ±‚å‡ºä½¿å¾—è¿™ä¸€ä¸ªä¼¼ç„¶å‡½æ•°çš„å€¼æœ€å¤§çš„å‚æ•°ä¼°è®¡ï¼š
$$
{max}_\vec{w}\quad L(\vec{W})
$$
å¯¹ä¸Šè¿°å…¬å¼è¿›è¡Œå˜æ¢ï¼Œç­‰ä»·äºå¦‚ä¸‹æœ€å°åŒ–é—®é¢˜ï¼š
$$
{min_\vec{w}} \quad-logL(\vec{W})
$$
ç„¶åæˆ‘ä»¬é‡å†™å…¬å¼(1)ï¼Œå¾—åˆ°ï¼š
$$
\begin{split}
{min}_\vec{W}\quad Err(\vec{W}) & =-log \prod_{i=1}^{m}h(x_n)^{y_n}(1-h(x_n))^{1-y_n}
\\& = -\sum_{n=1}^m y_nlog(h(x_n))+(1-y_n)log(1-h(x_n))
\\&=-\sum_{i=1}^{m}y_ilog\frac{p_i}{1-p_i}+log(1-p_i)
\\&=-\sum_{i=1}^{m}y_i\vec{W}^T\vec{x_1}-log(1+e^{\vec{W}^T\vec{x_1}})
\end{split}
\tag{6}
$$
è¿™å°±æ˜¯ç›®æ ‡å‡½æ•°çš„æœ€å°ä»£ä»·å‡½æ•°ï¼Œä¹Ÿç§°ä¸ºè¯¯å·®å‡½æ•°ï¼Œåœ¨ç»Ÿè®¡å­¦ä¸Šå«åšäº¤å‰ç†µã€‚è€Œä¸”ï¼Œè¯¥å‡½æ•°æ˜¯ä¸€ä¸ªè¿ç»­å¯å¯¼ï¼Œå¹¶ä¸”äºŒé˜¶å¯å¾®çš„å‡¸å‡½æ•°ã€‚æ ¹æ®å‡¸ä¼˜åŒ–ç†è®ºï¼Œå­˜åœ¨ä¸€ä¸ªå…¨å±€æœ€ä¼˜è§£ï¼Œä½¿å¾—$\nabla Err(\vec{w}) = 0$ã€‚æ‰€ä»¥ï¼Œå¯¹å…¬å¼(5)è¿›è¡Œæ±‚å¯¼å¯å¾—ï¼š
$$
\begin{split}
\frac{\partial L(\vec{W})}{\partial \vec{W}} & =-\sum_{i=1}^{m} (y_i-\frac{e^{\vec{W}^T\vec{x}}}{1+e^{\vec{W}^T\vec{x}}})\vec{x_i}
\\&=\sum_{i=1}^{m} (\frac{e^{\vec{W}^T\vec{x}}}{1+e^{\vec{W}^T\vec{x}}} -y_i )\vec{x_i}
\end{split}
\tag{7}
$$
ä¸Šå¼å°±æ˜¯è¯¯å·®å‡½æ•°çš„æ¢¯åº¦å…¬å¼ã€‚ç”±äºæˆ‘ä»¬éœ€è¦ä½¿å¾—ä¼¼ç„¶å‡½æ•°æœ€å¤§ï¼Œä¹Ÿå°±æ˜¯è¯¯å·®å‡½æ•°æœ€å°ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æ±‚è§£è¯¯å·®å‡½æ•°çš„é›¶ç‚¹ã€‚é€šè¿‡æ±‚å‡ºè¯¯å·®å‡½æ•°çš„æ¢¯åº¦ï¼Œå¯ä»¥åˆ©ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¥æ±‚è§£å‡½æ•°çš„é›¶ç‚¹ã€‚

æ‰€ä»¥ï¼Œæ ¹æ®æ¢¯åº¦ä¸‹é™æ³•ï¼Œæˆ‘ä»¬å¯ä»¥å°†æƒé‡$\vec{W}$çš„å…¬å¼è¿›è¡Œæ›´æ–°ï¼š
$$
\vec{W_{t+1}}=\vec{W_t}-\eta \nabla Err(\vec{W_t})\tag{8},\quad \etaä¸ºè¿­ä»£æ¢¯åº¦ä¸‹é™çš„æ­¥é•¿
$$
$\eta$æ˜¯è‡ªè¡Œè®¾å®šçš„å‚æ•°ï¼Œå®ƒæ˜¯ç®—æ³•è¿­ä»£æ˜¯å¯¹å‡½æ•°è¿›è¡Œæ›´æ–°çš„æ­¥é•¿ã€‚ç”±æ•°å€¼è®¡ç®—çš„çŸ¥è¯†å¯ä»¥ç›´åˆ°ï¼Œæ­¥é•¿è¶Šå°ï¼Œå¾—åˆ°çš„æœ€ä¼˜è§£å¯èƒ½æ€§è¶Šå¤§ï¼Œä½†æ˜¯ç®—æ³•è¿­ä»£æ‰€éœ€çš„æ¬¡æ•°ä¹Ÿè¶Šå¤šã€‚

æœ€åï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªæœ€ä¼˜è§£$\vec{W}$ï¼Œåˆ©ç”¨è¿™ä¸ªæœ€ä¼˜è§£ï¼Œä¾¿å¯ä»¥åˆ©ç”¨å…¬å¼(1)å¯¹æ ·æœ¬è¿›è¡Œé¢„æµ‹ã€‚



åœ¨è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œsigmoidå‡½æ•°è¢«ç”¨æ¥å°†è¾“å‡ºç©ºé—´$[-\infty, +\infty]$æ˜ å°„åˆ°$[0,1]$åŒºé—´ä¸Šï¼Œå°†è¾“å‡ºç©ºé—´å˜æˆæ ‡ç­¾çš„ä¼°è®¡æ¦‚ç‡ã€‚



### 2.ä¼ªä»£ç 

####æ¢¯åº¦ä¸‹é™æ³•è®¡ç®—$\vec{W}$

$$
\begin{split}
&inputï¼šè¿­ä»£æ¬¡æ•°generationã€è®­ç»ƒæ•°æ®X=\{\overrightarrow{x_1},\overrightarrow{x_2},...,\overrightarrow{x_n}\}
\\&output: \overrightarrow{W} 
\\&begin:
\\&\quad\quad initial\quad \vec{W_0}
\\&\quad\quad I_j=\sum_i w_{ij}O_i+\theta_j 

\\&\quad\quad\quad\quad		Err(\vec{W})=-\sum_{i=1}^{m}y_i\vec{W}^T\vec{x_1}-log(1+e^{\vec{W}^T\vec{x_1}})
\\&\quad\quad\quad\quad		\vec{W}=\vec{W}-\eta \nabla Err(\vec{W})
\\&end
\end{split}
$$

#### é¢„æµ‹

$$
\begin{split}
&inputï¼š\vec{W}ã€å¾…é¢„æµ‹æ•°æ®X=\{\overrightarrow{x_1},\overrightarrow{x_2},...,\overrightarrow{x_n}\}
\\&output: é¢„æµ‹æ ‡ç­¾\vec{Y}=\{\vec{y_1},...,\vec{y_n}\}
\\&begin:
\\&\quad\quad \vec{P}=\vec{X}.*\vec{W}
\\&\quad\quad for \quad i \quad to \quad n
\\&\quad\quad\quad\quad if\quad sigmoid(\vec{p_i})>0.5
\\&\quad\quad\quad\quad\quad\quad	\vec{y_i}=1
\\&\quad\quad\quad\quad else
\\&\quad\quad\quad\quad\quad\quad	\vec{y_i}=0
\\&\quad\quad return\quad \vec{Y}
\\&end
\end{split}
$$



### 3.å…³é”®ä»£ç ï¼ˆå¸¦æ³¨é‡Šï¼‰

#### æ‰¹æ¢¯åº¦æ›´æ–°$\vec{W}$

~~~python
def LR(eta, trainDataSet, trainLabelSet, IteraterTime) :
    w = ones(trainDataSet.shape[1])#è¿™é‡Œåˆ—æ•°ä¸ºç»´åº¦æ•°ï¼Œè¡Œæ•°ä¸ºæ ·æœ¬æ•°
    for i in range(IteraterTime) :
        wt = dot(trainDataSet,w)#æ›´æ–°å‚æ•°è€ƒè™‘æ‰€æœ‰æ ·æœ¬
        err = dot((sigmoid(wt) - trainLabelSet), trainDataSet)
        if len(err.nonzero()) == 0 :#åˆ¤æ–­è¯¯å·®æ˜¯å¦ä¸º0
            break
        else :
            w = w - eta * err
    return w
~~~



#### éšæœºæ¢¯åº¦æ›´æ–°$\vec{W}$

~~~python
def LRSingle(eta, trainDataSet, trainLabelSet, IteraterTime) :
    w = ones(trainDataSet.shape[1])              #è¿™é‡Œåˆ—æ•°ä¸ºç»´åº¦æ•°ï¼Œè¡Œæ•°ä¸ºæ ·æœ¬æ•°
    for i in range(IteraterTime) :
        for j in range(trainDataSet.shape[0]) :
            wt = trainDataSet[j] * w	#æ¯æ¬¡æ›´æ–°å‚æ•°è€ƒè™‘å•ä¸ªæ ·æœ¬
            err = (sigmoid(wt) - trainLabelSet[j]) * trainDataSet[j]
            if len(err.nonzero()) == 0 :
                break
            else :
                w = w - eta * err
    return w
~~~



### 4.åˆ›æ–°ç‚¹&ä¼˜åŒ–

#### å‘é‡åŒ–è¿ç®—

ç”±äºæœ¬æ¬¡å®éªŒä½¿ç”¨Pythonè¯­è¨€è¿›è¡Œï¼Œæ‰€ä»¥ä¸ºäº†æé«˜ç¨‹åºè¿è¡Œé€Ÿåº¦ä»¥åŠç®€åŒ–ä»£ç ï¼Œå¯¹ç¨‹åºä¸­çš„ç§‘å­¦è¿ç®—ä½¿ç”¨ä½¿ç”¨çŸ©é˜µæˆ–è€…å‘é‡è¿ç®—ã€‚

**éƒ¨åˆ†ä»£ç ï¼š** 

~~~python
def LR(eta, trainDataSet, trainLabelSet, IteraterTime) :
    w = ones(trainDataSet.shape[1])              #è¿™é‡Œåˆ—æ•°ä¸ºç»´åº¦æ•°ï¼Œè¡Œæ•°ä¸ºæ ·æœ¬æ•°
    for i in range(IteraterTime) :
        wt = dot(trainDataSet,w)
        err = dot((sigmoid(wt) - trainLabelSet), trainDataSet)
        if len(err.nonzero()) == 0 :
            break
        else :
            w = w - eta * err
    return w
~~~



#### éšæœºæ¢¯åº¦æ›´æ–°$\vec{W}$

ç”±äºæ‰¹æ¢¯åº¦ä¸‹é™æ¯è·Ÿæ–°ä¸€ä¸ªå‚æ•°çš„æ—¶å€™ï¼Œè¦ç”¨åˆ°æ‰€æœ‰çš„æ ·æœ¬æ•°ï¼Œæ‰€ä»¥è®­ç»ƒé€Ÿåº¦ä¼šéšç€æ ·æœ¬æ•°é‡çš„å¢åŠ è€Œå˜å¾—éå¸¸ç¼“æ…¢ã€‚ä¸ºäº†è®©$\vec{W}$æ›´å¥½åœ°æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œæé«˜æ”¶æ•›é€Ÿåº¦ï¼Œåˆ©ç”¨å•æ ·æœ¬å¯¹$\vec{W}$è¿›è¡Œæ›´æ–°ï¼Œå³åˆ©ç”¨ä¸€ä¸ªè®­ç»ƒæ ·æœ¬æ¥è®¡ç®—$Err(\vec{W})$ï¼Œç„¶åç«‹å³å¯¹$\vec{W}$è¿›è¡Œæ›´æ–°ã€‚ 



**å…³é”®ä»£ç ï¼š**

~~~python
def LRSingle(eta, trainDataSet, trainLabelSet, IteraterTime) :
    w = ones(trainDataSet.shape[1])              #è¿™é‡Œåˆ—æ•°ä¸ºç»´åº¦æ•°ï¼Œè¡Œæ•°ä¸ºæ ·æœ¬æ•°
    for i in range(IteraterTime) :
        for j in range(trainDataSet.shape[0]) :
            wt = trainDataSet[j] * w
            err = (sigmoid(wt) - trainLabelSet[j]) * trainDataSet[j]
            if len(err.nonzero()) == 0 :
                break
            else :
                w = w - eta * err
    return w
~~~



#### åŸºäºPIDåŠ¨æ€è°ƒæ•´$\vec{W}$

ç”±äºåœ¨æ¢¯åº¦ä¸‹é™æ³•å½“ä¸­ï¼Œå¦‚æœè¯¯å·®å‡½æ•°è¶Šå°ï¼Œè¿­ä»£çš„æ­¥é•¿åº”è¯¥è¶Šå°ï¼Œé¿å…$\vec{W}$åœ¨æœ€ä¼˜è§£é™„è¿‘éœ‡è¡ã€‚æ‰€ä»¥ï¼Œå¼•å…¥PIDç®—æ³•æ¥å¯¹$\vec{W}$çš„æ›´æ–°å¹…åº¦è¿›è¡Œæ§åˆ¶ï¼Œä½¿å¾—$\vec{W}$æ”¶æ•›åˆ°æœ€ä¼˜è§£ã€‚å…¶ä¸­$kp,ki,kd$å‚æ•°é€šè¿‡è°ƒå‚å¾—å‡ºçš„è¾ƒä¼˜å‚æ•°ã€‚

**ä¼ªä»£ç ï¼š**
$$
\begin{split}
&inputï¼š \overrightarrow{W} ã€Err( \overrightarrow{W} )ã€lastErrorã€ accumulateErrorã€deltaT
\\&output: \overrightarrow{W} 
\\&begin:
\\&\quad\quad	errorDifferential = (Err( \overrightarrow{W} ) - lastError) / deltaT
\\&\quad\quad	lastError = Err( \overrightarrow{W} )
\\&\quad\quad	accumulateError = accumulateError + err
\\&\quad\quad	kp = 0.5
\\&\quad\quad	ki = 3
\\&\quad\quad	kd = 0.012
\\&\quad\quad	\overrightarrow{W} =\overrightarrow{W}  - (kp * err + ki * accumulateError + kd * errorDifferential)
\\&end
\end{split}
$$
è¿™é‡Œå±•ç¤ºçš„ä¼ªä»£ç ä¸ºå•æ¬¡è¿­ä»£æ›´æ–°$\vec{W}$çš„PIDç®—æ³•ï¼Œæ¯æ¬¡ä¼ å‚$lastError,accumulateError$å¹¶ä¸”æ›´æ–°ã€‚å› ä¸ºPythoné‡Œé¢æ²¡æœ‰staticå…³é”®å­—ï¼Œæ‰€ä»¥é€šè¿‡ä¼ å‚å®ç°ä¿ç•™ä¸Šä¸€æ¬¡çš„å€¼ã€‚



**å…³é”®ä»£ç ï¼š**

~~~python
def pidDynamic(w, err, lastError, accumulateError) :
    errorDifferential = (err - lastError) / 0.0001
    lastError = err
    accumulateError = accumulateError + err
    kp = 0.5
    ki = 3
    kd = 0.012
    return w - (kp * err + ki * accumulateError + kd * errorDifferential), lastError, accumulateError
~~~



#### æ­£åˆ™åŒ–

ç”±äºlogisticså›å½’æ¨¡å‹å¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆçš„é—®é¢˜ï¼Œæ‰€ä»¥å¼•å…¥æ­£åˆ™åŒ–æ¥é™ä½æ¨¡å‹çš„è¿‡æ‹Ÿåˆç¨‹åº¦ã€‚æ­£åˆ™åŒ–æ˜¯ç»“æ„é£é™©æœ€å°åŒ–ç­–ç•¥çš„å®ç°ï¼Œæ˜¯åœ¨ç»éªŒé£é™©ä¸ŠåŠ ä¸€ä¸ªæ­£åˆ™åŒ–é¡¹(regularizer)æˆ–æƒ©ç½šé¡¹(penalty term)ã€‚æ­£åˆ™åŒ–é¡¹ä¸€èˆ¬æ˜¯æ¨¡å‹å¤æ‚åº¦çš„å•è°ƒé€’å¢å‡½æ•°ï¼Œæ¨¡å‹è¶Šå¤æ‚ï¼Œæ­£åˆ™åŒ–é¡¹å°±è¶Šå¤§ã€‚

æ­£åˆ™åŒ–çš„ä½œç”¨æ˜¯é€‰æ‹©ç»éªŒé£é™©æœ€å°å’Œæ¨¡å‹å¤æ‚åº¦åŒæ—¶è¾ƒå°çš„æ¨¡å‹ï¼›ä»è´å¶æ–¯ä¼°è®¡çš„è§’åº¦æ¥çœ‹ï¼Œæ­£åˆ™åŒ–é¡¹å¯¹åº”äºæ¨¡å‹çš„å…ˆéªŒæ¦‚ç‡ï¼›æ­£åˆ™åŒ–é€šè¿‡ä¿ç•™æ‰€æœ‰çš„ç‰¹å¾ï¼Œä½†æ˜¯å‡å°æŸäº›ç‰¹å¾çš„æƒé‡æ¥æ¶ˆé™¤æ¨¡å‹çš„è¿‡æ‹Ÿåˆï¼Œå…·ä½“å®ç°æ˜¯åœ¨åŸæœ‰çš„ä»£ä»·å‡½æ•°ä¸ŠåŠ ä¸Šæƒ©ç½šé¡¹ï¼Œæ‰€ä»¥ï¼Œé‡å†™å…¬å¼(6)ï¼š

$$
L(\vec{W})=[-\frac{1}{m}\sum_{i=1}^{m}y_ilogh(x_i)+(1-y_i)log(1-h(x_i))]+\frac{\lambda}{m} \sum_{j=1}^nw_j^2
\tag{9}
$$

åœ¨å…¬å¼(6)çš„åŸºç¡€ä¸Šï¼Œå…¬å¼(9)ä¸ä»…å¢åŠ äº†æƒ©ç½šé¡¹ï¼Œè€Œä¸”å°†è¯¯å·®å‡½æ•°é™¤ä»¥è®­ç»ƒé›†æ ·æœ¬æ•°é‡ï¼Œæ„ä¹‰åœ¨äºéœ€è¦æ¶ˆé™¤çš„è¯¯å·®å€¼æ˜¯æ¯ä¸€ä¸ªæ ·æœ¬çš„å¹³å‡è¯¯å·®å€¼ï¼Œé¿å…è®­ç»ƒæ•°æ®è¿‡å¤§å¯¼è‡´è¯¯å·®è¿‡å¤§ä½¿å¾—$\vec{W}$åœ¨æœ€ä¼˜è§£é™„è¿‘æŒ¯è¡ã€‚

å¯¹æƒ©ç½šé¡¹è¿›è¡Œæ±‚å¯¼ï¼Œå¯å¾—ï¼š
$$
\frac{\partial \frac{\lambda}{m} \sum_{j=1}^mw_j^2}{\partial \vec{w}}=\frac{2\lambda}{m} \sum_{j=1}^mw_j
\tag{10}
$$
æ‰€ä»¥ï¼Œé‡å†™å…¬å¼(7)ï¼Œå¾—åˆ°ï¼š
$$
\nabla Err(\vec{w}) =\frac{1}{m} \sum_{i=1}^{m} (\frac{e^{\vec{W}^T\vec{x}}}{1+e^{\vec{W}^T\vec{x}}} -y_i )\vec{x_i}+\frac{2\lambda}{m}\sum_{j=1}^nw_j
\tag{11}
$$
å¾—åˆ°æ–°çš„æ¢¯åº¦å…¬å¼ã€‚



**å…³é”®ä»£ç ï¼š**

~~~python
def regularLR(eta, trainDataSet, trainLabelSet, IteraterTime, Lambda) :
    w = ones(trainDataSet.shape[1])              #è¿™é‡Œåˆ—æ•°ä¸ºç»´åº¦æ•°ï¼Œè¡Œæ•°ä¸ºæ ·æœ¬æ•°
    for i in range(IteraterTime) :
        wt = dot(trainDataSet,w)
        err = dot((sigmoid(wt) - trainLabelSet), trainDataSet)
        err = err / trainDataSet.shape[0] + Lambda * sum(w) / trainDataSet.shape[0]
        # if sqrt(dot(err,err)) < 0.00001 :
        #     break
        # else :
        w = w - eta * err
    return w
~~~




## ä¸‰ã€å®éªŒç»“æœåŠåˆ†æ
### 1.å®éªŒç»“æœå±•ç¤ºç¤ºä¾‹

**å°æ•°æ®é›†ï¼š**

|  3   |  4   | 1(label) |
| :--: | :--: | :------: |
|  3   |  5   | 1(label) |
|  1   |  1   | 0(label) |
|  -3  |  -1  | 0(label) |



**ç¨‹åºä»¥0.1ä¸ºæ­¥é•¿å•æ¬¡æ›´æ–°$\vec{W}$ç»“æœï¼š**
$$
\vec{W}=(0.90004587,  0.91910797,  0.90968101)
$$
**éªŒç®—ï¼š**
$$
\begin{split}
\vec{S}&=
\left(
\begin{matrix}
1&3&4\\
1&3&5\\
1&1&1\\
1&-3&-1\\
\end{matrix}
\right)
\left(
\begin{matrix}
1\\
1\\
1\\
\end{matrix}
\right)=
\left(
\begin{matrix}
8\\
9\\
3\\
-3\\
\end{matrix}
\right)\\
\\
Err(\vec{W})&=
\left(
\begin{matrix}
(\frac{1}{1+e^8}-1)\times 1+(\frac{1}{1+e^9}-1)\times 1+(\frac{1}{1+e^3}-0)\times 1 +(\frac{1}{1+e^{-3}}-0)\times 1\\
(\frac{1}{1+e^8}-1)\times 3+(\frac{1}{1+e^9}-1)\times 3+(\frac{1}{1+e^3}-0)\times 1 +(\frac{1}{1+e^{-3}}-0)\times (-3)\\
(\frac{1}{1+e^8}-1)\times 4+(\frac{1}{1+e^9}-1)\times 5+(\frac{1}{1+e^3}-0)\times 1 +(\frac{1}{1+e^{-3}}-0)\times (-1)\\
\end{matrix}
\right)\\&=
\left(
\begin{matrix}
0.99954126\\
0.80892027\\
0.90318988\\
\end{matrix}
\right)\\
\\
\vec{W}&=
\left(
\begin{matrix}
1\\
1\\
1\\
\end{matrix}
\right)-0.1 \times
\left(
\begin{matrix}
0.99954126\\
0.80892027\\
0.90318988\\
\end{matrix}
\right)=
\left(
\begin{matrix}
0.90004587\\
0.91910797\\
0.90968101\\
\end{matrix}
\right)
\end{split}
$$
éªŒç®—ç»“æœå’Œç¨‹åºè¿è¡Œç»“æœä¸€è‡´ã€‚



### 2.è¯„æµ‹æŒ‡æ ‡å±•ç¤ºåŠåˆ†æ

**éªŒè¯é›†åˆ’åˆ†ï¼šåœ¨ç»™å®šæ•°æ®é›†çš„åŸºç¡€ä¸Šï¼Œä¹±åºä¹‹åæŒ‰ç…§è®­ç»ƒé›†ï¼šéªŒè¯é›†=3ï¼š1çš„æ¯”ä¾‹è¿›è¡Œåˆ’åˆ†ã€‚**



####å­¦ä¹ ç‡$\eta$å¯¹æ¨¡å‹å‡†ç¡®æ€§çš„å½±å“

**è¿­ä»£æ¬¡æ•°ï¼š200** 

![](./Batch.png)

![](Batch1.png)

å¦‚æœå•çº¯ä»éªŒè¯å‡†ç¡®ç‡æ¥çœ‹ï¼Œåœ¨ç®—æ³•è¿­ä»£200æ¬¡çš„å‰æä¸‹ï¼Œå¹¶ä¸æ˜¯å­¦ä¹ ç‡è¶Šå°è¶Šå¥½ã€‚ä»ä¸Šå›¾å¯ä»¥çœ‹å‡ºï¼Œå®éªŒæ¨¡å‹æœ€ä¼˜çš„å­¦ä¹ ç‡$\eta$ å¤§æ¦‚ä¸º0.16å·¦å³ï¼Œä»æ•´ä½“çš„è¶‹åŠ¿æ¥çœ‹ï¼Œå­¦ä¹ ç‡$\eta$è¶Šå°ï¼Œæ›´åŠ æœ‰åˆ©äºæ¢¯åº¦ä¸‹é™æ³•æ”¶æ•›åˆ°æœ€ä¼˜è§£ï¼Œå½“å­¦ä¹ ç‡$\eta$æ¯”è¾ƒå¤§çš„æ—¶å€™ï¼Œä¼šå¯¼è‡´$\vec{W}$åœ¨å‡½æ•°æœ€ä¼˜è§£é™„è¿‘æŒ¯è¡ã€‚



#### éšæœºæ¢¯åº¦ä¸‹é™å¯¹æ¨¡å‹å‡†ç¡®æ€§çš„å½±å“

**è¿­ä»£æ¬¡æ•°ï¼š200** 

![](Single.png)

ä»å›¾ä¸Šå¯ä»¥çœ‹åˆ°ï¼Œéšæœºæ¢¯åº¦ä¸‹é™æ–¹æ³•ä¼šä½¿å¾—æ±‚å‡ºçš„è§£åœ¨æœ€ä¼˜è§£é™„è¿‘ï¼Œæ±‚è§£$\vec{W}$å—å­¦ä¹ ç‡$\eta$å½±å“è¾ƒå°ã€‚ç”±äºè¿™ç§æ›´æ–°æ–¹æ³•éšæœºæ€§æ¯”è¾ƒå¼ºï¼Œæ‰€ä»¥éš¾ä»¥ç¡®å®šç®—æ³•æ±‚å‡ºçš„è§£æ˜¯å¦æ˜¯å…¨å±€æœ€ä¼˜è§£ã€‚



#### åŸºäºPIDåŠ¨æ€è°ƒæ•´$\vec{W}$æ¨¡å‹é¢„æµ‹èƒ½åŠ›

![](pid1.png)

![](pid.png)

ç”±äºPIDæ˜¯åŠ¨æ€å­¦ä¹ æ¸è¿›å¼é€¼è¿‘ç›®æ ‡å€¼çš„ç®—æ³•ï¼Œæ‰€ä»¥ï¼Œåœ¨ä¸€å®šçš„è¿­ä»£åŒºé—´å†…ï¼Œæ±‚å‡ºçš„æ¯ä¸€ä¸ª$\vec{W}$çš„å·®åˆ«å¹¶ä¸ä¼šå¾ˆå¤§ï¼Œä»å‡†ç¡®ç‡çš„å›¾ä¹Ÿå¯ä»¥çœ‹å‡ºæ¥ï¼Œæ¨¡å‹éªŒè¯çš„å‡†ç¡®ç‡åŸºæœ¬ä¿æŒåœ¨70%ä»¥ä¸Šï¼Œè¯´æ˜åŸºäºPIDçš„logisticså›å½’æ¨¡å‹å…·æœ‰è¾ƒå¼ºçš„é²æ£’æ€§ã€‚ä½†æ˜¯ï¼Œè¯¥ç®—æ³•å­˜åœ¨å‘¨æœŸæ€§çš„æŒ¯è¡é—®é¢˜ï¼ŒæŒ¯è¡å‘¨æœŸå¤§æ¦‚ä¸º200ã€‚ç»è¿‡åˆ†æï¼Œå› ä¸ºPIDç®—æ³•å½“ä¸­ä½¿ç”¨äº†è¯¯å·®ç§¯åˆ†ï¼Œæ¨ç®—å¤§æ¦‚æŒ¯è¡åŸå› æ˜¯è¯¯å·®ç§¯ç´¯å¯¼è‡´çš„è¯¯å·®ç§¯åˆ†è¿‡å¤§ï¼Œæ±‚å‡ºçš„è§£åç¦»æœ€ä¼˜è§£ã€‚å¦‚æœè¦è§£å†³è¯¥é—®é¢˜ï¼Œåº”è¯¥éœ€è¦é‡æ–°è°ƒå‚ï¼Œå°†è¯¯å·®ç§¯åˆ†æ¯”ä¾‹$ki$è°ƒä½ä¸€ä¸‹ï¼Œè¯¯å·®æ­¥é•¿$kp$è°ƒé«˜ä¸€äº›ã€‚



#### è¿ç”¨æ­£åˆ™åŒ–å‡è½»è¿‡æ‹Ÿåˆç¨‹åº¦

![](reg1.png)

åˆ©ç”¨äº†æ­£åˆ™åŒ–ï¼Œæ¨¡å‹çš„é¢„æµ‹å‡†ç¡®æ€§å¤§å¹…åº¦åœ°æé«˜äº†ï¼Œå¹¶ä¸”å¯¹æ¯ä¸ªè®­ç»ƒæ ·æœ¬çš„è¯¯å·®è¿›è¡Œäº†å¹³å‡åŒ–ï¼Œæ‰€ä»¥ä¸€å®šç¨‹åº¦ä¸Šå‡è½»äº†è¿‡æ‹Ÿåˆç¨‹åº¦ï¼ŒåŠ ä¸Šä½¿ç”¨äº†æƒ©ç½šé¡¹ï¼Œæ‰€ä»¥åœ¨æƒ©ç½šåŠ›åº¦é€‚å½“çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹å…·æœ‰å¾ˆå¥½çš„æ€§èƒ½ã€‚ä½†æ˜¯ï¼Œä»å‡†ç¡®ç‡çš„è¶‹åŠ¿æ¥çœ‹ï¼Œå¦‚æœæƒ©ç½šåŠ›åº¦è¿‡å¤§ï¼Œç‰¹å¾ä¹‹é—´çš„å·®å¼‚æ€§è¢«å¼±åŒ–äº†ï¼Œåè€Œä¼šä½¿æ¨¡å‹çš„å‡†ç¡®æ€§ä¸‹é™ã€‚



## å››ã€æ€è€ƒé¢˜

#### å¦‚æœæŠŠæ¢¯åº¦ä¸º0ï¼Œä½œä¸ºç®—æ³•åœæ­¢çš„æ¡ä»¶ï¼Œå¯èƒ½å­˜åœ¨æ€æ ·çš„å¼Šç«¯ï¼Ÿ

* è€ƒè™‘å‡½æ•°å¯èƒ½å­˜åœ¨å¤šä¸ªæå°å€¼ç‚¹ï¼Œå¦‚æœæŠŠæ¢¯åº¦ä¸ºé›¶ä½œä¸ºè¿­ä»£åœæ­¢æ¡ä»¶ï¼Œæ‰€ä»¥å¯èƒ½ä¼šå¯¼è‡´ç®—æ³•é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œè€Œå¾—ä¸åˆ°å…¨å±€æœ€ä¼˜è§£ã€‚å¦‚ä¸‹å›¾ï¼Œå¦‚æœå°†æ¢¯åº¦ä¸ºé›¶ä½œä¸ºè¿­ä»£åœæ­¢æ¡ä»¶ï¼Œå¾ˆå¯èƒ½ç®—æ³•åœ¨è®¡ç®—åˆ°$w'$ä¾¿åœæ­¢è®¡ç®—ï¼Œä½†$w'$å¹¶ä¸æ˜¯å…¨å±€æœ€ä¼˜è§£ã€‚

  ![](1.jpg)

* åœ¨å®é™…ä¸Šï¼Œ$\vec{W}$ä¼šåœ¨å‡½æ•°æœ€ä¼˜è§£é™„è¿‘éœ‡è¡ï¼Œå¦‚æœå°†æ¢¯åº¦ä¸ºé›¶ä½œä¸ºåœæ­¢æ¡ä»¶ï¼Œå¯èƒ½å¯¼è‡´ç®—æ³•è¿è¡Œæ—¶é—´è¿‡é•¿ç”šè‡³æ­»å¾ªç¯ã€‚

#### ğœ‚ çš„å¤§å°ä¼šæ€ä¹ˆå½±å“æ¢¯åº¦ä¸‹é™çš„ç»“æœï¼Ÿç»™å‡ºå…·ä½“çš„è§£é‡Šï¼Œå¯è§†åŒ–çš„è§£é‡Šæœ€å¥½ï¼Œæ¯”å¦‚å›¾å½¢å±•ç¤ºç­‰

* $\eta$è¿‡å°ï¼šä¼šå¯¼è‡´æ”¶æ•›çš„é€Ÿåº¦æ¯”è¾ƒæ…¢ï¼Œå¦‚ä¸‹å›¾åéƒ¨åˆ†

* $\eta$è¿‡å¤§ï¼šä¼šå‡ºç°éœ‡è¡çš„ç°è±¡ï¼Œå³è·³è¿‡æœ€ä¼˜è§£ï¼Œåœ¨æœ€ä¼˜è§£é™„è¿‘å¾˜å¾Šï¼Œå¦‚ä¸‹å›¾å³éƒ¨åˆ†

  ![](2.jpg)

#### æ‰¹æ¢¯åº¦ä¸‹é™å’Œéšæœºæ¢¯åº¦ä¸‹é™çš„ä¼˜ç¼ºç‚¹

* ä¼˜ç‚¹ï¼š
  * æ‰¹æ¢¯åº¦ï¼šæ”¶æ•›å’Œæ¢¯åº¦ä¸‹é™æ›´åŠ å¹³ç¨³ï¼Œå®¹æ˜“æ”¶æ•›åˆ°å…¨å±€æœ€ä¼˜è§£
  * éšæœºæ¢¯åº¦ï¼šè¿­ä»£å’Œæ”¶æ•›é€Ÿåº¦å¿«
* ç¼ºç‚¹ï¼š
  * æ‰¹æ¢¯åº¦ï¼šä¸‹é™å’Œæ”¶æ•›çš„é€Ÿåº¦æ…¢ï¼Œå½“æ•°æ®æ ·æœ¬éå¸¸å¤šçš„æ—¶å€™ï¼Œç®—æ³•è¿è¡Œååˆ†è€—æ—¶ï¼Œ
  * éšæœºæ¢¯åº¦ï¼šå™ªéŸ³è¾ƒå¤šï¼Œä½¿å¾—æ¯æ¬¡éƒ½ä¸ä¸€å®šå‘ç€æ•´ä½“æœ€ä¼˜åŒ–æ–¹å‘ï¼Œè¿­ä»£å®¹æ˜“é™·å…¥åˆ°å±€éƒ¨æœ€ä¼˜è§£ä¸­







